import socket
import time
from datetime import datetime
import jieba.analyse
from loguru import logger
import feedparser
from flask import Flask, request, render_template, redirect, url_for, jsonify
from celery import Celery
from db_manager import DatabaseManager
from tool import get_feed_entry, insert_feed, insert_keyword, get_keywords_from_deepseek

app = Flask(__name__)
app.config['SECRET_KEY'] = 'top-secret!'

# Celery configuration
app.config['CELERY_BROKER_URL'] = 'redis://:5bAlEv0xt4tV@192.168.133.132:16379/3'
app.config['CELERY_RESULT_BACKEND'] = 'redis://:5bAlEv0xt4tV@192.168.133.132:16379/3'
app.config['CELERY_INCLUDE'] = []

# Initialize Celery
celery = Celery(app.name, broker=app.config['CELERY_BROKER_URL'])
celery.conf.update(app.config)

FEED_DICT = {
    "feed://eugene-wei.squarespace.com/blog?format=rss": "technology/blog",
}


@celery.task(bind=True)
def get_feed_info(self):
    all_entries = []

    for feed_url, fclass in FEED_DICT.items():
        for entry in get_feed_entry(feed_url):
            url = entry.get('url', '') or entry.get('link', '')
            title = entry.get('title', '')
            description = entry.get('description', '')
            feed_id = insert_feed(url, title, description)
            if feed_id:
                for feed_class in fclass.split('/'):
                    insert_keyword(feed_id, feed_class)

    return {
        'current': len(all_entries),
        'total': len(all_entries),
        'status': 'Task completed!',
        'result': len(all_entries)
    }


@celery.task(name="tag_unprocessed_feeds")
def tag_unprocessed_feeds():
    db = DatabaseManager()

    # æŸ¥è¯¢æœªæ‰“æ ‡ç­¾çš„ feeds
    query = "SELECT id, url FROM feeds WHERE is_tagged = 0 LIMIT 50"
    feeds = db.execute_query(query, fetch=True)

    if not feeds:
        logger.info("âœ… æ²¡æœ‰æœªå¤„ç†çš„ feeds")
        return {"result": 0, "status": "No untagged feeds"}

    insert_keyword_query = """
        INSERT INTO keyword (feed_id, keyword, created_at, updated_at)
        VALUES (%s, %s, %s, %s)
    """

    update_feed_tagged_query = "UPDATE feeds SET is_tagged = 1 WHERE id = %s"

    tagged_count = 0
    for feed in feeds:
        feed_id = feed['id']
        url = feed['url']
        keywords = get_keywords_from_deepseek(url)
        logger.info(f"ğŸ”– ä¸º Feed ID {feed_id} æå–å…³é”®è¯: {keywords}")
        for kw in keywords:
            try:
                insert_keyword(feed_id, kw)
                logger.info(f"âœ… æ’å…¥å…³é”®è¯ '{kw}' åˆ° feed {feed_id}")
            except Exception as e:
                logger.warning(f"âŒ æ’å…¥å¤±è´¥ï¼ˆFeed ID {feed_id} / å…³é”®è¯ï¼š{kw}ï¼‰ï¼š{e}")

        try:
            db.execute_query(update_feed_tagged_query, (feed_id,))
            tagged_count += 1
        except Exception as e:
            logger.warning(f"âš ï¸ æ ‡è®° feed {feed_id} å·²æ‰“æ ‡ç­¾å¤±è´¥ï¼š{e}")
    logger.info(f"ğŸ‰ å…±å¤„ç†å¹¶æ‰“æ ‡ç­¾ {tagged_count} æ¡ feed")
    return {"result": tagged_count, "status": "Completed"}


# =======================================================================================================================

@app.route('/api/feeds_with_keywords', methods=['GET'])
def get_feeds_with_keywords():
    db = DatabaseManager()

    # è·å–åˆ†é¡µå‚æ•°
    try:
        page = int(request.args.get('page', 1))
        page_size = int(request.args.get('page_size', 10))
        if page < 1 or page_size < 1:
            raise ValueError()
    except ValueError:
        return jsonify({"error": "Invalid pagination parameters"}), 400

    offset = (page - 1) * page_size

    # æ­£ç¡®åˆ†é¡µ feedsï¼ˆåªæŸ¥ä¸»è¡¨ï¼‰
    feed_query = """
        SELECT id, url, title, description, is_tagged
        FROM feeds
        ORDER BY id DESC
        LIMIT %s OFFSET %s
    """
    feeds = db.execute_query(feed_query, (page_size, offset), fetch=True)

    if not feeds:
        return jsonify({
            'server_ip': socket.gethostbyname(socket.gethostname()),
            'page': page,
            'page_size': page_size,
            'total': 0,
            'feeds': []
        })

    # æ”¶é›†æ‰€æœ‰ feed_id è¿›è¡Œå…³é”®è¯æŸ¥è¡¨
    feed_ids = [feed['id'] for feed in feeds]
    keyword_query = """
        SELECT feed_id, keyword FROM keyword WHERE feed_id IN %s
    """
    keyword_rows = db.execute_query(keyword_query, (feed_ids,), fetch=True)

    # æ„å»ºå…³é”®è¯æ˜ å°„
    keyword_map = {}
    for row in keyword_rows:
        keyword_map.setdefault(row['feed_id'], []).append(row['keyword'])

    # æŠŠ keyword é™„åŠ å› feed æ•°æ®
    for feed in feeds:
        feed['is_tagged'] = bool(feed['is_tagged'])
        feed['keywords'] = keyword_map.get(feed['id'], [])

    # æ€»æ•°é‡
    total = db.execute_query("SELECT COUNT(*) AS total FROM feeds", fetch=True)[0]['total']

    return jsonify({
        'server_ip': socket.gethostbyname(socket.gethostname()),
        'page': page,
        'page_size': page_size,
        'total': total,
        'feeds': feeds
    })


if __name__ == '__main__':
    app.run(debug=True, host="0.0.0.0")

    # task = get_feed_info.apply_async()
    # print(task.id)  # å¯ç”¨äºæŸ¥çœ‹çŠ¶æ€
    # task = tag_unprocessed_feeds.apply_async()
    # print(task.id)  # å¯ç”¨äºæŸ¥çœ‹çŠ¶æ€
